_target_: optimol.models.pdbbind_module.PDBbindLitModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  weight_decay: 0.001

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 100000

net:
  _target_: src.models.components.gnn.GNN
  n_global_features: 0
  n_atom_types: 17
  n_atom_embeddings: 357 #37 #357
  n_edge_features: 47
  gnn_embedding:
    convolution_type: sageconv
    atom_embedding_sizes: [64, 64] # atom convolution sizes
    activation: relu
    batch_norm: true
    dropout: 0.4
    atom_update_aggregation: add
    readout_pooling: [add]
    readout_mlp_layer_sizes: []
    skip_connections: true
  global_embedding:
    hidden_layer_sizes: []
    n_output_features: 256
    activation: relu
    apply_output_activation: true
    batch_norm: true
    dropout: 0.4
  output_net_configs:
    hidden_layer_sizes: [64]
    activation: relu 
    apply_output_activation: false
    batch_norm: true
    dropout: 0.4

# compile model for faster training with pytorch 2.0
compile: false
